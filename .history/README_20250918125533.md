# Hướng dẫn triển khai và sử dụng

## ⊠ Các bước triển khai
1. Cài đặt Python (khuyến nghị >=3.8).
2. Cài đặt các thư viện cần thiết bằng lệnh:
   ```bash
   pip install -r requirements.txt
   ```
3. Đảm bảo các file dữ liệu (UD_English-EWT) đã có trong thư mục dự án.
4. Kiểm tra lại cấu trúc thư mục:
   - src/
   - test/
   - UD_English-EWT/
   - requirements.txt
   - README.md

## Cách chạy code và ghi log kết quả
- Để chạy thử nghiệm và ghi log kết quả, sử dụng lệnh:
  ```bash
  python -m test.test_lab1 > log.txt
  ```
- Kết quả sẽ được ghi vào file `log.txt` trong thư mục gốc.

##  Giải thích các kết quả thu được
- Kết quả in ra gồm:
  - Đoạn văn bản mẫu được lấy từ bộ dữ liệu.
  - Kết quả tokenization bằng các tokenizer khác nhau (SimpleTokenizer, RegexTokenizer).
  - So sánh số lượng và chất lượng token giữa các phương pháp.

### Ví dụ kết quả thực tế

```
--- Tokenizing Sample Text from UD_English-EWT ---
Original Sample: Al-Zaman : American forces killed Shaikh Abdullah al-Ani, the preacher at the
mosque in the town of ...
SimpleTokenizer Output (first 20 tokens): ['al-zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al-ani,', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim,', 'near', 'the']
RegexTokenizer Output (first 20 tokens): ['al', 'zaman', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', 'ani', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', 'near']
```

- **Nhận xét:**
  - `SimpleTokenizer` giữ lại dấu câu và các ký tự đặc biệt như dấu gạch ngang, dấu phẩy, dấu hai chấm.
  - `RegexTokenizer` tách các từ, loại bỏ dấu câu, giúp chuẩn hóa token cho các tác vụ NLP.
  - Số lượng token và nội dung token sẽ khác nhau tùy tokenizer, phản ánh chiến lược tách từ khác nhau.

## Khó khăn gặp phải và cách giải quyết
- **Lỗi import module**: Đã thêm file `__init__.py` vào các thư mục để Python nhận diện package.
- **Đường dẫn dữ liệu**: Đảm bảo chạy script từ thư mục gốc dự án hoặc điều chỉnh đường dẫn tương đối.
- **Encoding**: Một số file dữ liệu cần mở với encoding 'utf-8'.

## • Model tạo sẵn, prompt
- Không sử dụng model tạo sẵn ngoài các tokenizer tự cài đặt trong thư mục `src/preprocessing`.
